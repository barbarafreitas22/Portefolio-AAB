{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metabolic Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: building and analyzing a metabolic network derived from biochemical reaction data. The goal is to understand how metabolites interact, determine their significance within the network, and simulate how metabolic reactions unfold from a given starting point.\n",
    "\n",
    "**Data (e-coli.txt)**\n",
    "\n",
    "- Ecoli.txt contains biochemical reactions, each listed on a separate line.\n",
    "- Reactions follow a standardized format, where substrates produce one or more products:\n",
    "- A parser extracts and structures these reactions into a usable format, organizing them into dictionaries of substrates and products.\n",
    "\n",
    "**Network Construction**\n",
    "\n",
    "A custom graph structure (MN_Graph) is implemented to model the metabolic network.\n",
    "Each metabolite is represented as a node.\n",
    "Edges are created between metabolites that participate together in the same reaction.\n",
    "The resulting graph captures the biochemical connectivity of the system.\n",
    "\n",
    "**Centrality and Network Metrics**\n",
    "\n",
    "To assess the influence of each metabolite, the network is analyzed using standard centrality measures:\n",
    "Degree Centrality: Counts of direct connections a node has.\n",
    "Closeness Centrality: Measures how easily a node can reach others in the network.\n",
    "Betweenness Centrality: Highlights nodes that frequently occur on the shortest paths between other nodes.\n",
    "These metrics help identify the most critical metabolites in terms of connectivity and influence.\n",
    "\n",
    "**Dynamic Simulation of Metabolic Propagation**\n",
    "\n",
    "Starting from an initial list of known metabolites, the system simulates how reactions progress:\n",
    "identifies active reactions and adds newly produced products to the known set until there is no new metabolites.\n",
    "\n",
    "**Results**\n",
    "\n",
    "A ranked list of key metabolites based on centrality analysis.\n",
    "The final set of metabolites that can be synthesized.\n",
    "\n",
    "**Use Cases**\n",
    "\n",
    "This type of analysis is valuable for:\n",
    "Exploring and optimizing metabolic pathways.\n",
    "Identifying targets for metabolic engineering.\n",
    "Simulating biological behavior in synthetic biology applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Graphs import MyGraph\n",
    "import re\n",
    "import heapq\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class MN_Graph(MyGraph):\n",
    "    \"\"\"\n",
    "    Specialized graph class for metabolite networks, extending Graph with methods \n",
    "    for analyzing node degrees, centrality, and clustering.\n",
    "    \"\"\"\n",
    "    def __init__(self, g = {}):\n",
    "        super().__init__(g)\n",
    "\n",
    "    def all_degrees(self, deg_type=\"inout\"):\n",
    "        \"\"\"\n",
    "        Return node degrees based on direction: 'in', 'out', or both.\n",
    "        \"\"\"\n",
    "        degs = {}\n",
    "        for v in self.graph:\n",
    "            if deg_type in (\"out\", \"inout\"):\n",
    "                degs[v] = len(self.graph[v])\n",
    "            else:\n",
    "                degs[v] = 0\n",
    "        if deg_type in (\"in\", \"inout\"):\n",
    "            for v in self.graph:\n",
    "                for d in self.graph[v]:\n",
    "                    if deg_type == \"in\" or v not in self.graph.get(d, []):\n",
    "                        degs[d] = degs.get(d, 0) + 1\n",
    "        return degs\n",
    "\n",
    "    def highest_degrees(self, all_deg=None, deg_type=\"inout\", top=10):\n",
    "        \"\"\"\n",
    "        Return top nodes by degree.\n",
    "        Parameters:\n",
    "            all_deg (dict): Degree dict.\n",
    "            deg_type (str): Degree type.\n",
    "            top (int): Number of top nodes to return.\n",
    "        \"\"\"\n",
    "        if all_deg is None:\n",
    "            all_deg = self.all_degrees(deg_type)\n",
    "        return sorted(all_deg, key=all_deg.get, reverse=True)[:top]\n",
    "\n",
    "    def mean_degree(self, deg_type=\"inout\"):\n",
    "        \"\"\"\n",
    "        Calculate average degree of all nodes.\n",
    "        \"\"\"\n",
    "        degs = self.all_degrees(deg_type)\n",
    "        return sum(degs.values()) / len(degs)\n",
    "\n",
    "    def prob_degree(self, deg_type=\"inout\"):\n",
    "        \"\"\"\n",
    "        Return the node degrees distribution as a probability.\n",
    "        Parameters:\n",
    "            deg_type (str): Degree type.\n",
    "\n",
    "        Returns:\n",
    "            dict: Degree value to probability.\n",
    "        \"\"\"\n",
    "        degs = self.all_degrees(deg_type)\n",
    "        hist = {}\n",
    "        for d in degs.values():\n",
    "            hist[d] = hist.get(d, 0) + 1\n",
    "        return {k: v / len(degs) for k, v in hist.items()}\n",
    "\n",
    "    def mean_distances(self):\n",
    "        \"\"\"\n",
    "        Compute the average of shortest path length and the density of the graph.\n",
    "        \"\"\"\n",
    "        total_dist = 0\n",
    "        count = 0\n",
    "        for node in self.get_nodes():\n",
    "            for _, dist in self.reachable_with_dist(node):\n",
    "                total_dist += dist\n",
    "            count += len(self.reachable_with_dist(node))\n",
    "        mean_dist = total_dist / count if count else 0\n",
    "        n = len(self.get_nodes())\n",
    "        density = count / (n * (n - 1)) if n > 1 else 0\n",
    "        return mean_dist, density\n",
    "\n",
    "    def closeness_centrality(self, node):\n",
    "        \"\"\"\n",
    "        Returns closeness centrality for a given node.\n",
    "        \"\"\"\n",
    "        dists = self.reachable_with_dist(node)\n",
    "        if not dists:\n",
    "            return 0.0\n",
    "        return len(dists) / sum(dist for _, dist in dists)\n",
    "\n",
    "    def highest_closeness(self, top=10):\n",
    "        \"\"\"\n",
    "        Returns nodes with highest closeness centrality.\n",
    "        \"\"\"\n",
    "        centrality = {n: self.closeness_centrality(n) for n in self.get_nodes()}\n",
    "        return sorted(centrality, key=centrality.get, reverse=True)[:top]\n",
    "\n",
    "    def betweenness_centrality(self, node):\n",
    "        \"\"\"\n",
    "        Approximate betweenness centrality for a node.\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        through = 0\n",
    "        for s in self.get_nodes():\n",
    "            for t in self.get_nodes():\n",
    "                if s != t and s != node and t != node:\n",
    "                    path = self.shortest_path(s, t)\n",
    "                    if path:\n",
    "                        total += 1\n",
    "                        if node in path:\n",
    "                            through += 1\n",
    "        return through / total if total > 0 else 0\n",
    "\n",
    "    def clustering_coef(self, v):\n",
    "        \"\"\"\n",
    "        Computes local clustering coefficient for a node.\n",
    "        \"\"\"\n",
    "        neighbors = self.get_adjacents(v)\n",
    "        if len(neighbors) <= 1:\n",
    "            return 0.0\n",
    "        links = 0\n",
    "        for i in neighbors:\n",
    "            for j in neighbors:\n",
    "                if i != j and (j in self.get_successors(i) or i in self.get_successors(j)):\n",
    "                    links += 1\n",
    "        return links / (len(neighbors) * (len(neighbors) - 1))\n",
    "\n",
    "    def all_clustering_coefs(self):\n",
    "        \"\"\"\n",
    "        Returns clustering coefficients for all nodes.\n",
    "        \"\"\"\n",
    "        return {v: self.clustering_coef(v) for v in self.get_nodes()}\n",
    "\n",
    "    def mean_clustering_coef(self):\n",
    "        \"\"\"\n",
    "        Average clustering coefficient across all nodes.\n",
    "        \"\"\"\n",
    "        cc = self.all_clustering_coefs()\n",
    "        return sum(cc.values()) / len(cc) if cc else 0.0\n",
    "\n",
    "    def mean_clustering_perdegree(self, deg_type=\"inout\"):\n",
    "        \"\"\"\n",
    "        Average clustering coefficient grouped by degree.\n",
    "        \"\"\"\n",
    "        degs = self.all_degrees(deg_type)\n",
    "        ccs = self.all_clustering_coefs()\n",
    "        grouped = {}\n",
    "        for node, deg in degs.items():\n",
    "            grouped.setdefault(deg, []).append(ccs[node])\n",
    "        return {k: sum(v) / len(v) for k, v in grouped.items()}\n",
    "\n",
    "\n",
    "class CentralityAnalyzer:\n",
    "    \"\"\"\n",
    "    Centrality calculator using various metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "\n",
    "    def degree_centrality(self):\n",
    "        \"\"\"\n",
    "        Return degree centrality of each node.\n",
    "        \"\"\"\n",
    "        return {n: len(self.graph.get_successors(n)) for n in self.graph.get_nodes()}\n",
    "\n",
    "    def closeness_centrality(self):\n",
    "        \"\"\"\n",
    "        Return closeness centrality for all nodes.\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for node in self.graph.get_nodes():\n",
    "            dist, count = self._bfs_total_distance_and_reach_count(node)\n",
    "            result[node] = (count / dist) if dist > 0 else 0.0\n",
    "        return result\n",
    "\n",
    "    def _bfs_total_distance_and_reach_count(self, start):\n",
    "        \"\"\"\n",
    "        Breadth-first traversal for closeness computation.\n",
    "        \"\"\"\n",
    "        visited = set()\n",
    "        queue = deque([(start, 0)])\n",
    "        total, count = 0, 0\n",
    "        while queue:\n",
    "            node, dist = queue.popleft()\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                if node != start:\n",
    "                    total += dist\n",
    "                    count += 1\n",
    "                queue.extend((n, dist + 1) for n in self.graph.get_successors(node) if n not in visited)\n",
    "        return total, count\n",
    "\n",
    "    def betweenness_centrality(self):\n",
    "        \"\"\"\n",
    "        Compute node betweenness using Brandes' algorithm.\n",
    "        \"\"\"\n",
    "        centrality = dict.fromkeys(self.graph.get_nodes(), 0.0)\n",
    "        for s in self.graph.get_nodes():\n",
    "            stack = []\n",
    "            pred = {w: [] for w in self.graph.get_nodes()}\n",
    "            sigma = dict.fromkeys(self.graph.get_nodes(), 0)\n",
    "            dist = dict.fromkeys(self.graph.get_nodes(), -1)\n",
    "            sigma[s], dist[s] = 1, 0\n",
    "            queue = deque([s])\n",
    "            while queue:\n",
    "                v = queue.popleft()\n",
    "                stack.append(v)\n",
    "                for w in self.graph.get_successors(v):\n",
    "                    if dist[w] < 0:\n",
    "                        dist[w] = dist[v] + 1\n",
    "                        queue.append(w)\n",
    "                    if dist[w] == dist[v] + 1:\n",
    "                        sigma[w] += sigma[v]\n",
    "                        pred[w].append(v)\n",
    "            delta = dict.fromkeys(self.graph.get_nodes(), 0)\n",
    "            while stack:\n",
    "                w = stack.pop()\n",
    "                for v in pred[w]:\n",
    "                    delta[v] += (sigma[v] / sigma[w]) * (1 + delta[w])\n",
    "                if w != s:\n",
    "                    centrality[w] += delta[w]\n",
    "        return centrality\n",
    "\n",
    "    def top_nodes(self, centrality_dict, top_n=5):\n",
    "        \"\"\"\n",
    "        Return highest ranked nodes by centrality score.\n",
    "        \"\"\"\n",
    "        return heapq.nlargest(top_n, centrality_dict.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "def parse_reactions(file_path):\n",
    "    \"\"\"\n",
    "    Parse reaction data into structured reaction dictionaries.\n",
    "    \"\"\"\n",
    "    reactions = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            if ':' not in line:\n",
    "                continue\n",
    "            parts = re.split(r':\\s*', line.strip(), maxsplit=1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            reaction_id, formula = parts\n",
    "            match = re.match(r\"(.*?)\\s*(<=>|=>)\\s*(.*)\", formula)\n",
    "            if not match:\n",
    "                continue\n",
    "            substrates = [s.strip() for s in match.group(1).split('+')]\n",
    "            products = [p.strip() for p in match.group(3).split('+')]\n",
    "            reactions.append({'id': reaction_id, 'substrates': substrates, 'products': products})\n",
    "    return reactions\n",
    "\n",
    "\n",
    "def build_metabolite_graph(reactions):\n",
    "    \"\"\"\n",
    "    Build a metabolite interaction graph from reaction data.\n",
    "    \"\"\"\n",
    "    g = MN_Graph()\n",
    "    for r in reactions:\n",
    "        compounds = r['substrates'] + r['products']\n",
    "        for i in range(len(compounds)):\n",
    "            for j in range(i + 1, len(compounds)):\n",
    "                g.add_edge(compounds[i], compounds[j], 1)\n",
    "                g.add_edge(compounds[j], compounds[i], 1)\n",
    "    return g\n",
    "\n",
    "\n",
    "def get_active_reactions(metabolites_set, reactions):\n",
    "    \"\"\"\n",
    "    Return reactions that can occur with the available substrates.\n",
    "    \"\"\"\n",
    "    return [r for r in reactions if all(m in metabolites_set for m in r['substrates'])]\n",
    "\n",
    "def get_produced_metabolites(active_reactions):\n",
    "    \"\"\"\n",
    "    Extract products from active reactions.\n",
    "    \"\"\"\n",
    "    return set(p for r in active_reactions for p in r['products'])\n",
    "\n",
    "def compute_final_metabolites(initial_metabolites, reactions):\n",
    "    \"\"\"\n",
    "    Iteratively expand metabolite set by applying reactions.\n",
    "    \"\"\"\n",
    "    known = set(initial_metabolites)\n",
    "    while True:\n",
    "        active = get_active_reactions(known, reactions)\n",
    "        new = get_produced_metabolites(active)\n",
    "        if new.issubset(known):\n",
    "            break\n",
    "        known.update(new)\n",
    "    return known\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reactions parsed: 931\n",
      "\n",
      "Degree Centrality:\n",
      "M_h_c: 2170\n",
      "M_h2o_c: 1279\n",
      "M_atp_c: 863\n",
      "M_pi_c: 683\n",
      "M_adp_c: 675\n",
      "\n",
      "Closeness Centrality:\n",
      "M_h_c: 0.8342\n",
      "M_h2o_c: 0.6909\n",
      "M_atp_c: 0.6056\n",
      "M_pi_c: 0.5910\n",
      "M_adp_c: 0.5864\n",
      "\n",
      "Betweenness Centrality:\n",
      "M_h_c: 348835.9756\n",
      "M_h2o_c: 137598.9464\n",
      "M_pi_c: 33431.8987\n",
      "M_atp_c: 25958.4243\n",
      "M_adp_c: 16836.3095\n",
      "\n",
      "Initial Metabolites:\n",
      "['M_glc_DASH_D_c', 'M_h2o_c', 'M_nad_c', 'M_atp_c']\n",
      "\n",
      "Reachable Metabolites After Propagation:\n",
      "['M_13dpg_c', 'M_23ddhb_c', 'M_23dhb_c', 'M_23dhba_c', 'M_23dhmb_c', 'M_2dda7p_c', 'M_2ddg6p_c', 'M_2me4p_c', 'M_34hpp_c', 'M_3dhq_c', 'M_3dhsk_c', 'M_3mob_c', 'M_3psme_c', 'M_4hbz_c', 'M_4per_c', 'M_6pgc_c', 'M_6pgl_c', 'M_ade_c', 'M_adn_c', 'M_adp_c', 'M_adphep_DASH_DD_c', 'M_adphep_DASH_LD_c', 'M_alac_DASH_S_c', 'M_amp_c', 'M_ara5p_c', 'M_atp_c', 'M_camp_c', 'M_cbp_c', 'M_chor_c', 'M_co2_c', 'M_db4p_c', 'M_dha_c', 'M_dhap_c', 'M_dnad_c', 'M_dxyl5p_c', 'M_e4p_c', 'M_f6p_c', 'M_fdp_c', 'M_for_c', 'M_fprica_c', 'M_g3p_c', 'M_g6p_c', 'M_glc_DASH_D_c', 'M_gmhep17bp_c', 'M_gmhep1p_c', 'M_gmhep7p_c', 'M_h2_c', 'M_h2o_c', 'M_h_c', 'M_hco3_c', 'M_hxan_c', 'M_ichor_c', 'M_imp_c', 'M_ins_c', 'M_kdo8p_c', 'M_kdo_c', 'M_mthgxl_c', 'M_nac_c', 'M_nad_c', 'M_nadh_c', 'M_nadp_c', 'M_nadph_c', 'M_ncam_c', 'M_nh4_c', 'M_nicrnt_c', 'M_nmn_c', 'M_oaa_c', 'M_ohpb_c', 'M_pep_c', 'M_phpyr_c', 'M_pi_c', 'M_pphn_c', 'M_ppi_c', 'M_prbamp_c', 'M_prbatp_c', 'M_prfp_c', 'M_prlp_c', 'M_prpp_c', 'M_pyr_c', 'M_r1p_c', 'M_r5p_c', 'M_ru5p_DASH_D_c', 'M_s7p_c', 'M_skm5p_c', 'M_skm_c', 'M_xan_c', 'M_xmp_c', 'M_xtsn_c', 'M_xu5p_DASH_D_c']\n"
     ]
    }
   ],
   "source": [
    "# Path to the file containing metabolic reactions\n",
    "reactions_file = \"ecoli.txt\"\n",
    "\n",
    "# Load and parse the reactions data from the file\n",
    "parsed_reactions = parse_reactions(reactions_file)\n",
    "print(f\"Number of reactions parsed: {len(parsed_reactions)}\")\n",
    "\n",
    "# -------------------------\n",
    "# Centrality Analysis \n",
    "# -------------------------\n",
    "\n",
    "# Create a graph where metabolites are nodes and edges represent joint participation in reactions\n",
    "metabolite_graph = build_metabolite_graph(parsed_reactions)\n",
    "\n",
    "# Instantiate the centrality analyzer using the constructed graph\n",
    "centrality_analyzer = CentralityAnalyzer(metabolite_graph)\n",
    "\n",
    "# Calculate and display degree centrality (number of direct connections)\n",
    "print(\"\\nDegree Centrality:\")\n",
    "for metabolite, degree_val in centrality_analyzer.top_nodes(centrality_analyzer.degree_centrality()):\n",
    "    print(f\"{metabolite}: {degree_val}\")\n",
    "\n",
    "# Calculate and display closeness centrality (based on average shortest path distance)\n",
    "print(\"\\nCloseness Centrality:\")\n",
    "for metabolite, closeness_val in centrality_analyzer.top_nodes(centrality_analyzer.closeness_centrality()):\n",
    "    print(f\"{metabolite}: {closeness_val:.4f}\")\n",
    "\n",
    "# Calculate and display betweenness centrality (frequency of node on shortest paths)\n",
    "print(\"\\nBetweenness Centrality:\")\n",
    "for metabolite, betweenness_val in centrality_analyzer.top_nodes(centrality_analyzer.betweenness_centrality()):\n",
    "    print(f\"{metabolite}: {betweenness_val:.4f}\")\n",
    "\n",
    "# --------------------------------\n",
    "# Metabolite Reachability Analysis\n",
    "# --------------------------------\n",
    "\n",
    "# Define the initial set of metabolites available\n",
    "initial_metabolites = [\"M_glc_DASH_D_c\", \"M_h2o_c\", \"M_nad_c\", \"M_atp_c\"]\n",
    "\n",
    "# Determine the full set of metabolites reachable from the initial set through reactions\n",
    "reachable_metabolites = compute_final_metabolites(initial_metabolites, parsed_reactions)\n",
    "\n",
    "# Output the initial and final sets of metabolites after propagation\n",
    "print(\"\\nInitial Metabolites:\")\n",
    "print(initial_metabolites)\n",
    "\n",
    "print(\"\\nReachable Metabolites After Propagation:\")\n",
    "print(sorted(reachable_metabolites))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
